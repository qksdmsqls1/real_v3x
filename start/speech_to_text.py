# speech_to_text.py

import sounddevice as sd
import numpy as np
import whisper
import scipy.io.wavfile as wav
import tempfile
from gpt_response import get_gpt_response  # GPT í•¨ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
from text_to_speech import speak  # TTS í•¨ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°

SAMPLE_RATE = 16000
DURATION = 5  # ì´ˆ ë‹¨ìœ„ ë…¹ìŒ ì‹œê°„

def record_audio():
    print("ğŸ™ ìŒì„±ì„ ë…¹ìŒí•˜ì„¸ìš”... (5ì´ˆ)")
    audio = sd.rec(int(DURATION * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=1, dtype='float32')
    sd.wait()
    print("âœ… ë…¹ìŒ ì™„ë£Œ!")
    return audio

def save_temp_wav(audio):
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
        wav.write(f.name, SAMPLE_RATE, (audio * 32767).astype(np.int16))
        return f.name

def transcribe(audio_path):
    model = whisper.load_model("base")  # í•„ìš”í•œ ê²½ìš° "small", "medium"ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥
    result = model.transcribe(audio_path, language="ko")
    return result["text"]

if __name__ == "__main__":
    audio = record_audio()
    wav_path = save_temp_wav(audio)
    text = transcribe(wav_path)
    print(f"ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸: {text}")

    # GPTì— í…ìŠ¤íŠ¸ ë³´ë‚´ê³  ì‘ë‹µ ë°›ê¸°
    gpt_answer = get_gpt_response(text)
    print(f"ğŸ¤– GPT ì‘ë‹µ: {gpt_answer}")

    # ìŒì„±ìœ¼ë¡œ ì‘ë‹µ ì½ê¸°
    speak(gpt_answer)
